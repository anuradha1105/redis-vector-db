{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet redis openai python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNpgy5KQZIPG",
        "outputId": "baae2359-58c9-45e0-da18-955e5274d4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/339.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m337.9/339.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis(\n",
        "    host=\"redis-19387.c232.us-east-1-2.ec2.redns.redis-cloud.com\",\n",
        "    port=19387,\n",
        "    password=\"******************************\",\n",
        "    ssl=False,             # üëà turn OFF TLS\n",
        "    decode_responses=False\n",
        ")\n",
        "\n",
        "print(\"Ping Redis:\", r.ping())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHhPmCWNcS_e",
        "outputId": "ec85c67b-9c55-4b5e-abd2-83f457f2761f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ping Redis: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"redis>=5.0.0\" redisvl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "XmnE0jBJfBL0",
        "outputId": "43ca2e39-0347-4e0f-b5f0-cf36d7543cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: redis>=5.0.0 in /usr/local/lib/python3.12/dist-packages (7.0.1)\n",
            "Collecting redisvl\n",
            "  Downloading redisvl-0.10.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting jsonpath-ng>=1.5.0 (from redisvl)\n",
            "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from redisvl) (0.5.3)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from redisvl) (2.0.2)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from redisvl) (2.11.10)\n",
            "Collecting python-ulid>=3.0.0 (from redisvl)\n",
            "  Downloading python_ulid-3.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.4 in /usr/local/lib/python3.12/dist-packages (from redisvl) (6.0.3)\n",
            "Collecting redis>=5.0.0\n",
            "  Downloading redis-6.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.12/dist-packages (from redisvl) (8.5.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath-ng>=1.5.0->redisvl) (3.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->redisvl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->redisvl) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->redisvl) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->redisvl) (0.4.2)\n",
            "Downloading redisvl-0.10.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m161.4/161.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-6.4.0-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
            "Downloading python_ulid-3.1.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: redis, python-ulid, jsonpath-ng, redisvl\n",
            "  Attempting uninstall: redis\n",
            "    Found existing installation: redis 7.0.1\n",
            "    Uninstalling redis-7.0.1:\n",
            "      Successfully uninstalled redis-7.0.1\n",
            "Successfully installed jsonpath-ng-1.7.0 python-ulid-3.1.0 redis-6.4.0 redisvl-0.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "redis"
                ]
              },
              "id": "661edd9b04a0403fbfb9d71bccd82e39"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redis.commands.search.field import TextField, VectorField\n",
        "from redis.commands.search.index_definition import IndexDefinition, IndexType\n"
      ],
      "metadata": {
        "id": "sxnwSvy-fKqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis(\n",
        "    host=\"redis-19387.c232.us-east-1-2.ec2.redns.redis-cloud.com\",\n",
        "    port=19387,\n",
        "    password=\"***********************\",\n",
        "    ssl=False,\n",
        "    decode_responses=False\n",
        ")\n",
        "\n",
        "print(\"Ping Redis:\", r.ping())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QlkIt7YfgKF",
        "outputId": "94c184a5-e179-4a5e-abf4-633802636b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ping Redis: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redis.commands.search.field import TextField, VectorField\n",
        "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
        "\n",
        "INDEX_NAME = \"idx:docs\"\n",
        "DOC_PREFIX = \"doc:\"\n",
        "VECTOR_DIM = 1536\n",
        "DISTANCE_METRIC = \"COSINE\"\n",
        "\n",
        "# drop existing index if any\n",
        "try:\n",
        "    r.ft(INDEX_NAME).dropindex(delete_documents=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "schema = (\n",
        "    TextField(\"title\"),\n",
        "    TextField(\"content\"),\n",
        "    VectorField(\n",
        "        \"embedding\",\n",
        "        \"HNSW\",\n",
        "        {\n",
        "            \"TYPE\": \"FLOAT32\",\n",
        "            \"DIM\": VECTOR_DIM,\n",
        "            \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "\n",
        "r.ft(INDEX_NAME).create_index(\n",
        "    schema,\n",
        "    definition=IndexDefinition(prefix=[DOC_PREFIX], index_type=IndexType.HASH),\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Redis vector index created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNCCvfW5fofX",
        "outputId": "f50b3685-1fd4-49fd-ff40-ce4b3a461c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Redis vector index created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str):\n",
        "    resp = client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=text\n",
        "    )\n",
        "    return resp.data[0].embedding\n",
        "\n",
        "def float32_to_bytes(vec):\n",
        "    return np.array(vec, dtype=np.float32).tobytes()\n",
        "\n",
        "docs = [\n",
        "    {\n",
        "        \"id\": \"1\",\n",
        "        \"title\": \"Redis vector search\",\n",
        "        \"content\": \"Redis Stack supports vector similarity search using RediSearch.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"2\",\n",
        "        \"title\": \"OpenAI embeddings\",\n",
        "        \"content\": \"OpenAI embeddings convert text into numerical vectors for semantic search.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"3\",\n",
        "        \"title\": \"Caching embeddings in Redis\",\n",
        "        \"content\": \"Embeddings can be cached in Redis to avoid recomputing them and speed up queries.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "for d in docs:\n",
        "    emb = get_embedding(d[\"content\"])\n",
        "    key = f\"{DOC_PREFIX}{d['id']}\"\n",
        "    r.hset(\n",
        "        key,\n",
        "        mapping={\n",
        "            \"title\": d[\"title\"],\n",
        "            \"content\": d[\"content\"],\n",
        "            \"embedding\": float32_to_bytes(emb),\n",
        "        },\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Inserted\", len(docs), \"docs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "GvcQqMOBfwIN",
        "outputId": "08476a89-a41b-4b62-90dd-a3eff96dd827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2642137688.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{DOC_PREFIX}{d['id']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     r.hset(\n",
            "\u001b[0;32m/tmp/ipython-input-2642137688.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     resp = client.embeddings.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"redis>=5.0.0\" python-dotenv openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "wpkwQ5Plg-VQ",
        "outputId": "4a3a9bd6-3eab-4849-e7c2-2f71993ec0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: redis>=5.0.0 in /usr/local/lib/python3.12/dist-packages (6.4.0)\n",
            "Collecting redis>=5.0.0\n",
            "  Using cached redis-7.0.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting openai\n",
            "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Using cached redis-7.0.1-py3-none-any.whl (339 kB)\n",
            "Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis, openai\n",
            "  Attempting uninstall: redis\n",
            "    Found existing installation: redis 6.4.0\n",
            "    Uninstalling redis-6.4.0:\n",
            "      Successfully uninstalled redis-6.4.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.109.1\n",
            "    Uninstalling openai-1.109.1:\n",
            "      Successfully uninstalled openai-1.109.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "redisvl 0.10.0 requires redis<7.0,>=5.0, but you have redis 7.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-2.6.1 redis-7.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "redis"
                ]
              },
              "id": "a8d91824d235478da5a6b14741e82acc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis(\n",
        "    host=\"redis-19387.c232.us-east-1-2.ec2.redns.redis-cloud.com\",\n",
        "    port=19387,\n",
        "    password=\"*************************\",\n",
        "    ssl=False,\n",
        "    decode_responses=False,\n",
        ")\n",
        "\n",
        "print(\"Ping Redis:\", r.ping())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpIHa6ZShFuD",
        "outputId": "aa3a5a49-3a24-459f-f4c2-6a1d2af79a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ping Redis: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# put your real key here\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"*************************\"\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"  # 1536-dim\n"
      ],
      "metadata": {
        "id": "LU5T9ADDhY97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from redis.commands.search.field import TextField, VectorField\n",
        "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
        "\n",
        "INDEX_NAME = \"idx:docs\"\n",
        "DOC_PREFIX = \"doc:\"\n",
        "VECTOR_DIM = 1536\n",
        "DISTANCE_METRIC = \"COSINE\"\n",
        "\n",
        "\n",
        "try:\n",
        "    r.ft(INDEX_NAME).dropindex(delete_documents=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "schema = (\n",
        "    TextField(\"title\"),\n",
        "    TextField(\"content\"),\n",
        "    VectorField(\n",
        "        \"embedding\",\n",
        "        \"HNSW\",\n",
        "        {\n",
        "            \"TYPE\": \"FLOAT32\",\n",
        "            \"DIM\": VECTOR_DIM,\n",
        "            \"DISTANCE_METRIC\": DISTANCE_METRIC,\n",
        "        },\n",
        "    ),\n",
        ")\n",
        "\n",
        "r.ft(INDEX_NAME).create_index(\n",
        "    schema,\n",
        "    definition=IndexDefinition(\n",
        "        prefix=[DOC_PREFIX],\n",
        "        index_type=IndexType.HASH,\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Redis vector index created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-T9ioPbhctH",
        "outputId": "e1e549be-5275-4d5c-84c8-fab29db30a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Redis vector index created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    resp = client.embeddings.create(\n",
        "        model=EMBEDDING_MODEL,\n",
        "        input=text\n",
        "    )\n",
        "    return resp.data[0].embedding\n",
        "\n",
        "def float32_to_bytes(vec):\n",
        "    return np.array(vec, dtype=np.float32).tobytes()\n",
        "\n",
        "docs = [\n",
        "    {\n",
        "        \"id\": \"1\",\n",
        "        \"title\": \"Redis vector search\",\n",
        "        \"content\": \"Redis Stack supports vector similarity search using RediSearch.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"2\",\n",
        "        \"title\": \"OpenAI embeddings\",\n",
        "        \"content\": \"OpenAI embeddings convert text into numerical vectors for semantic search.\",\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"3\",\n",
        "        \"title\": \"Caching embeddings in Redis\",\n",
        "        \"content\": \"Embeddings can be cached in Redis so we do not recompute them for every query.\",\n",
        "    },\n",
        "]\n"
      ],
      "metadata": {
        "id": "ixxk-RQShgfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in docs:\n",
        "    emb = get_embedding(d[\"content\"])\n",
        "    key = f\"{DOC_PREFIX}{d['id']}\"\n",
        "    r.hset(\n",
        "        key,\n",
        "        mapping={\n",
        "            \"title\": d[\"title\"],\n",
        "            \"content\": d[\"content\"],\n",
        "            \"embedding\": float32_to_bytes(emb),\n",
        "        },\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Inserted\", len(docs), \"docs into Redis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "2iJZkagzhkBN",
        "outputId": "4fc19035-bc42-4c51-dc45-6fb1d0f442c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2805810533.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{DOC_PREFIX}{d['id']}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     r.hset(\n\u001b[1;32m      5\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2848142455.py\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     resp = client.embeddings.create(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    emb = model.encode(text)\n",
        "    return emb.tolist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496,
          "referenced_widgets": [
            "46d96fe5188542f7a1e71e63eb5aa30b",
            "3f03678029b3407694f1dae6c5f9a8db",
            "9cdd79e247f24efe9ee729eb25a87715",
            "9d6353b058484898a12884b7ef3e0151",
            "936bf105d5254f1ebd0ef39e2a3349d0",
            "6d3939daae564bf1af626ac32e9c28a3",
            "6d1c6dbb9295490480518b30203f26ef",
            "e6cb522329e24e259c86b73de7509315",
            "16d72adf439c42499da5915204eff7c5",
            "beb2dd93ebed4b6c8103d02b0b94d4da",
            "fc2251f8c23548dab735b33f9a16c2cd",
            "479ca08f7a5048d5a0b899cae0d1511d",
            "0a45a68f2f144285a052f7ce37fd8414",
            "6632b3cfa580419b954aaf179e19d5f3",
            "fc928ef9337a45c4baa0d529d9ae775c",
            "2164427f64df4415b7b3b8329f5f4ff4",
            "ecb7c574aec449bb945d1ea792b5edd8",
            "94a367e48ffb45c8a80c6d31e0d83eb0",
            "a3e1e9effe6a41fc9eee5c078311d37f",
            "441db8f73a4e4c05bde4e187f59246cd",
            "1e79543f27374d81adac07dfd0fbd73f",
            "855b1b4431e44069bdcd88ab1c441af4",
            "1e64033582754014b78f2f712e80e916",
            "cbd09c5340d24a209c920f7f15c6c03e",
            "6af2af38544746f2b7c6b505690f1704",
            "845405bbe64546019396685179563d5a",
            "959220a3172043159038b11cef8027e3",
            "d11d71241f504109ae0b6a6eb84b231a",
            "cbec7d3638504462ac72a63f1efaa1ab",
            "759049c0da61498e8cdf99ab52e3737b",
            "1409171e215b47288e7ce316269d47e1",
            "84942ccfa8974701b768a1237a4b8b41",
            "7a2230f89a024f4099cf45a64b358ef1",
            "d0c2ef34c8fa47f4a7152977a88f9e21",
            "a7a6b95098574d689d17d617d05f0c77",
            "023097df73e043e1be592cae65e01ed0",
            "4047936f031d478abcf0bf8055a4b2bb",
            "0a08924cb945441b90b58ee0e4dd7ffe",
            "7a3558a7d0ff468bbec7e6a1748fa615",
            "c1d363a9fb0145c49f9a169943e01cdf",
            "a2bcf3037ae54d0787e8dd91f0dc60b5",
            "5e5b8bf5af5349e59c3be517bf7dc181",
            "741851f9cd7346e8be28ce8695b1b68e",
            "fd5dca77acd0414db7a61fdb1b42ec12",
            "5e4294a08eba45a9acf0192412287163",
            "5bfe613da7784664904a615061ca4480",
            "0529da14e0e04e2cb7dfb4a2f40f750a",
            "d4f3fe9853674e389b15d2c8e5c80e33",
            "a8f56eb3ec20470da52766da376ad336",
            "73996a2d7d404a6992acf42d54b73381",
            "a1ff2aaf93ba4028ae35e8e56f5f6f3f",
            "c17edc96ffc042548f4a5bcef00ca641",
            "7d70ced7ef94425081a32b757e859082",
            "290020f277b646758dc14db22d50fcb4",
            "a15e903053d449c9a4bea741ea058e92",
            "87417c708ae04e18af21fb8b426c64bf",
            "e16b39baeb3a45a5b8a6043a60fc5e5e",
            "58af95d5385a4c469eb09a0286c7a46a",
            "fd8f563496554177beaba0af23103ba4",
            "e521c779c7124c3fa6f2b3aa7f1a2d9d",
            "eb346a4106fa4e29bc8cdacff86c8421",
            "38ed1fc671804fbca1265c3225ef2f3e",
            "aded62396b4444ccaa6c8ad05cc5adc5",
            "ee4123877494472e83d5d5456a6739b2",
            "bd73681039134cd5a3d840818660947a",
            "4ebe2b1102294337975a3f1e784961d6",
            "f45524004051455b9604da8bec43aad2",
            "345f524aa27141eeb4908dafa280362c",
            "4f1754370c9a4c009ff448695424a0c2",
            "0dae95d1d3514205b8df5d90f60dbbdc",
            "66bd99e46631446e9506d6c610a7cf96",
            "da3d1352a7d24457a25b6387a0d65295",
            "f700f9acfd7142ad8f6443683cb4e591",
            "9eb0aaf452fb47d586921a289bf89fc6",
            "3301ba65410a45b4b8ed97a0d2d2e08e",
            "9cd2420025534f1e8e1a2d805e0b800c",
            "34af06983e5543a4b1e4f43c08f8022d",
            "0c52d244815d47d18ed2b5896d29d0b7",
            "b3a0f816fe85484181f54dc8ad93aee0",
            "f7839e39aac54b869bb02d24431c4173",
            "fda09380ed9b44b795e2705743ed9bac",
            "cdb60d858d9246469cc5ce599e14e2a0",
            "0062f375bc3447b0bb0f620038a59835",
            "1f06b93544404ec58d322efcb4fe923a",
            "7f6bcd36b09f42fabcd902b19dde5a72",
            "a1f90b90809f419cb733575318269741",
            "bbe6347b99f84bb7940728604f4c4c42",
            "5d51bfdc35b14ceaa7aa1a12d14b9204",
            "ec5b2b09c83f4a018e816e158f25b6f4",
            "34353c3f9489480da64508dd4b3e7da0",
            "d4bb853f2f8447b38c7f2403fbd2736b",
            "5f8b99e60be04a3884113345953eca04",
            "eb35ed380fb8479993d6eb9c3bc5a0a3",
            "a73260dda31c4c2eb9e7d15632c52555",
            "f95e81d1a4d747e09f0a503baedc325a",
            "e496d7d71c8c44129d0759200113b6c9",
            "ef33e7809e754ef4b398da419246cb95",
            "3d3cc331849242a59707ac84c0d39b11",
            "bac91d01c6ea460c95f049c1f6baf5f1",
            "70910aaa991d4a8d945d1b25a19346fa",
            "0d19766d018b4de19668e7c17c98db5c",
            "5099dfc531764534a665b9a5fb496ccb",
            "3c28707680fb4063b84765e29e929e98",
            "13a102bfd43e48ee8fa995e5d65f8fcf",
            "53adc4c41e0241e587a2dab74b771d2a",
            "a110762446fe4782a0e3a467f119ce85",
            "f95ce3fde30748de93d5276e4acf7120",
            "6638e889ad3444f29d9d139aa19a1d03",
            "224e8fb2eaff4c7d80a4e0ee957ec79d",
            "cd5bd6743ea54cf0aa642ef730004dce",
            "1614c3649e0e4df1807ef93c80e77d26",
            "2b517eb9b2764a0ca380d0157bfea150",
            "05bbcdb6e7494baab2750af2209f3736",
            "734392192a6247949b3dc8c7bc41abd4",
            "0fa35fae572242ff9c315e8c8cb3e3f0",
            "28d6f766e2024ceab014be629bf237b1",
            "1b5eb1a7224645fd9af74b0b7a9daf02",
            "e182500ca2db468299cc5a1a9a5bba98",
            "f257f69361da449b8fdf8cba9f7c9909",
            "9c57f334a5204a1ab2a4826cb25da86c",
            "869bb776255040d79a2cd2d58b460012"
          ]
        },
        "id": "c9_gDtT2jL9N",
        "outputId": "51b481be-0240-4554-c015-e223ff7f25d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46d96fe5188542f7a1e71e63eb5aa30b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "479ca08f7a5048d5a0b899cae0d1511d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e64033582754014b78f2f712e80e916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c2ef34c8fa47f4a7152977a88f9e21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e4294a08eba45a9acf0192412287163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87417c708ae04e18af21fb8b426c64bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f45524004051455b9604da8bec43aad2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c52d244815d47d18ed2b5896d29d0b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec5b2b09c83f4a018e816e158f25b6f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70910aaa991d4a8d945d1b25a19346fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1614c3649e0e4df1807ef93c80e77d26"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Redis Stack supports vector similarity search.\"\n",
        "vec = get_embedding(sample)\n",
        "print(\"Embedding length:\", len(vec))\n",
        "print(\"First 5 numbers:\", vec[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsdlEglyjm9J",
        "outputId": "850858d4-e561-4992-b9bc-b1c32e255909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 384\n",
            "First 5 numbers: [-0.05443801358342171, -0.09366077929735184, -0.10989154130220413, -0.04881509393453598, 0.02446616068482399]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redis.commands.search.field import TextField, VectorField\n",
        "from redis.commands.search.index_definition import IndexDefinition, IndexType\n",
        "\n",
        "INDEX_NAME = \"idx:docs\"\n",
        "DOC_PREFIX = \"doc:\"\n",
        "VECTOR_DIM = 384            # new dimension\n",
        "DISTANCE_METRIC = \"COSINE\"\n",
        "\n",
        "try:\n",
        "    r.ft(INDEX_NAME).dropindex(delete_documents=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "schema = (\n",
        "    TextField(\"title\"),\n",
        "    TextField(\"content\"),\n",
        "    VectorField(\n",
        "        \"embedding\",\n",
        "        \"HNSW\",\n",
        "        {\"TYPE\": \"FLOAT32\", \"DIM\": VECTOR_DIM, \"DISTANCE_METRIC\": DISTANCE_METRIC},\n",
        "    ),\n",
        ")\n",
        "\n",
        "r.ft(INDEX_NAME).create_index(\n",
        "    schema,\n",
        "    definition=IndexDefinition(prefix=[DOC_PREFIX], index_type=IndexType.HASH),\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Redis vector index created (384-dim model)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxbfB0jyjrMY",
        "outputId": "9a138a5c-a7bf-46f6-c5e9-2d04524988a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Redis vector index created (384-dim model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    {\"id\": \"1\", \"title\": \"Redis vector search\", \"content\": \"Redis Stack supports vector similarity search using RediSearch.\"},\n",
        "    {\"id\": \"2\", \"title\": \"Sentence Transformers\", \"content\": \"Sentence Transformers generate text embeddings locally without API keys.\"},\n",
        "    {\"id\": \"3\", \"title\": \"Caching embeddings\", \"content\": \"Embeddings can be cached in Redis to speed up semantic search queries.\"},\n",
        "]\n",
        "\n",
        "for d in docs:\n",
        "    emb = get_embedding(d[\"content\"])\n",
        "    key = f\"{DOC_PREFIX}{d['id']}\"\n",
        "    r.hset(\n",
        "        key,\n",
        "        mapping={\n",
        "            \"title\": d[\"title\"],\n",
        "            \"content\": d[\"content\"],\n",
        "            \"embedding\": float32_to_bytes(emb),\n",
        "        },\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ Inserted\", len(docs), \"docs into Redis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjZZB1sbjvPb",
        "outputId": "f35853a4-fb18-4c0e-ed88-5f31ec66dd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Inserted 3 docs into Redis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redis.commands.search.query import Query\n",
        "\n",
        "def query_redis(query_text: str, k: int = 3):\n",
        "    q_emb = get_embedding(query_text)\n",
        "    base_query = f\"*=>[KNN {k} @embedding $vec_param AS score]\"\n",
        "    q = (\n",
        "        Query(base_query)\n",
        "        .sort_by(\"score\")\n",
        "        .return_fields(\"title\", \"content\", \"score\")\n",
        "        .paging(0, k)\n",
        "        .dialect(2)\n",
        "    )\n",
        "    params = {\"vec_param\": float32_to_bytes(q_emb)}\n",
        "    res = r.ft(INDEX_NAME).search(q, query_params=params)\n",
        "    return res\n",
        "\n",
        "# Test\n",
        "results = query_redis(\"how can I use redis for semantic search?\")\n",
        "for i, doc in enumerate(results.docs, 1):\n",
        "    print(i, doc.title, \"-\", doc.score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X-sw0nWjy0r",
        "outputId": "e1df2c2c-746d-49dc-9279-953d5f79a84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Caching embeddings - 0.252403378487\n",
            "2 Redis vector search - 0.352478146553\n",
            "3 Sentence Transformers - 0.837117254734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I built a Redis Vector Database to store and search embeddings for semantic queries. Initially, I used OpenAI‚Äôs text-embedding-3-small model to generate the vectors, but ran into a RateLimitError since my OpenAI account had no credits left.\n",
        "\n",
        "To get around that, I switched to a free alternative ‚Äî the all-MiniLM-L6-v2 model from Hugging Face. It runs locally in Google Colab and doesn‚Äôt require an API key, which made things a lot easier.\n",
        "\n",
        "I updated the Redis index to support 384 dimensions, and all the documents were successfully stored. When I tested it with semantic queries, Redis returned accurate and relevant matches.\n",
        "\n",
        "Overall, the project successfully created a working vector database with cached embeddings in Redis, making it possible to handle user queries efficiently."
      ],
      "metadata": {
        "id": "phErYYHckNZ9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}